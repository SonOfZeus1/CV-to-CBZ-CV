name: Pipeline - Extract Emails

on:
  schedule:
    - cron: '*/15 * * * *'
  workflow_dispatch:


concurrency:
  group: ${{ github.workflow }}-${{ github.ref }}
  cancel-in-progress: false

jobs:
  extract-emails:
    runs-on: ubuntu-latest
    permissions:
      contents: 'read'
      id-token: 'write'
      actions: 'read'

    steps:
    - name: Check Schedule & Previous Run
      if: github.event_name == 'schedule'
      id: check_schedule
      env:
        GH_TOKEN: ${{ github.token }}
      run: |
        json=$(gh run list --repo ${{ github.repository }} --workflow pipeline_extract_emails.yml --status completed --limit 10 --json conclusion,createdAt,updatedAt,databaseId)
        
        python3 -c "
        import sys, json, datetime, os
        from datetime import timezone

        try:
            data = json.loads('''$json''')
        except:
            data = []

        now = datetime.datetime.now(timezone.utc)
        found_real_run = False
        should_skip = 'false'
        
        for run in data:
            start = datetime.datetime.fromisoformat(run['createdAt'].replace('Z', '+00:00'))
            end = datetime.datetime.fromisoformat(run['updatedAt'].replace('Z', '+00:00'))
            duration = (end - start).total_seconds()
            
            print(f'Run {run.get(\"databaseId\")}: {run[\"conclusion\"]}, {duration}s')
            
            if duration > 45: # 45s threshold to be safe
                found_real_run = True
                if run['conclusion'] == 'failure':
                    print('Last real run FAILED. Aborting.')
                    sys.exit(1) # Fail the job
                
                elapsed = (now - end).total_seconds()
                print(f'Elapsed: {elapsed}s')
                
                if elapsed < 900:
                    print('Too soon. Skipping.')
                    should_skip = 'true'
                else:
                    print('Time OK.')
                break
        
        with open(os.environ['GITHUB_OUTPUT'], 'a') as fh:
            fh.write(f'skip={should_skip}\n')
        "
        
    - name: Stop if Skipping
      if: steps.check_schedule.outputs.skip == 'true'
      run: |
        echo "Skipping this run (Gap < 15 mins)."
        exit 0 # This marks step as success, but we need to stop subsequent steps.
        # There is no 'exit workflow' command.
        # We must use 'if' conditions on ALL subsequent steps.
        # Or fail? If we fail, it looks red. User wants 'Success' probably?
        # Actually, user said 'Change logic so it launches...'.
        # If I fail, the next check sees a Failure and stops forever.
        # So I MUST succeed.
        # I will cancel the workflow using API? No, that's 'Cancelled'.
        # I will just let this step pass, and add 'if: steps.check_schedule.outputs.skip != 'true'' to the main step.

    - name: Checkout repository
      if: steps.check_schedule.outputs.skip != 'true'
      uses: actions/checkout@v3

    - name: Authenticate to Google Cloud
      if: steps.check_schedule.outputs.skip != 'true'
      uses: google-github-actions/auth@v1
      with:
        workload_identity_provider: ${{ secrets.GCP_WORKLOAD_IDENTITY_PROVIDER }}
        service_account: ${{ secrets.GCP_SERVICE_ACCOUNT }}
        audience: ${{ secrets.GCP_AUDIENCE }}

    - name: Set up Python
      if: steps.check_schedule.outputs.skip != 'true'
      uses: actions/setup-python@v4
      with:
        python-version: '3.11'

    - name: Install dependencies
      if: steps.check_schedule.outputs.skip != 'true'
      run: |
        sudo apt-get update
        sudo apt-get install -y tesseract-ocr
        python -m pip install --upgrade pip
        pip install google-api-python-client google-auth-httplib2 google-auth-oauthlib PyMuPDF python-docx pytesseract nltk Pillow groq dateparser python-dotenv Jinja2 WeasyPrint python-dateutil openai
        python -m nltk.downloader stopwords punkt averaged_perceptron_tagger

    - name: Run script
      if: steps.check_schedule.outputs.skip != 'true'
      env:
        EMAIL_SHEET_ID: ${{ secrets.EMAIL_SHEET_ID }}
        EMAIL_SOURCE_FOLDER_ID: ${{ secrets.EMAIL_SOURCE_FOLDER_ID }}
        EMAIL_SHEET_NAME: ${{ secrets.EMAIL_SHEET_NAME }}
        OPENROUTER_API_KEY: ${{ secrets.OPENROUTER_API_KEY }}
      run: python extract_emails.py --folder_id "$EMAIL_SOURCE_FOLDER_ID" --sheet_id "$EMAIL_SHEET_ID" --sheet_name "${EMAIL_SHEET_NAME:-Feuille 1}"
