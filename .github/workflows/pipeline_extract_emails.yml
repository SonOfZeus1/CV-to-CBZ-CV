name: Pipeline - Extract Emails

on:
  workflow_dispatch:
  schedule:
    - cron: '*/5 * * * *'

concurrency:
  group: ${{ github.workflow }}-${{ github.ref }}
  cancel-in-progress: false

jobs:
  extract-emails:
    runs-on: ubuntu-latest
    permissions:
      contents: 'read'
      id-token: 'write'
      actions: 'read'

    steps:
    - name: Check previous run status & timing
      if: github.event_name == 'schedule'
      env:
        GH_TOKEN: ${{ github.token }}
      run: |
        # Fetch last 10 runs with details
        # We need createdAt and updatedAt to calculate duration
        RUNS=$(gh run list --workflow pipeline_extract_emails.yml --status completed --limit 10 --json conclusion,createdAt,updatedAt,databaseId)
        
        # Current time in seconds
        NOW=$(date +%s)
        
        # Iterate to find the last "Real" run (duration > 30s)
        # We use jq to filter and sort, or just loop in bash. 
        # Let's use a simple loop over the JSON array.
        
        echo "$RUNS" | jq -c '.[]' | while read -r run; do
          CONCLUSION=$(echo "$run" | jq -r '.conclusion')
          CREATED_AT=$(echo "$run" | jq -r '.createdAt')
          UPDATED_AT=$(echo "$run" | jq -r '.updatedAt')
          ID=$(echo "$run" | jq -r '.databaseId')
          
          # Convert to timestamps
          START_TS=$(date -d "$CREATED_AT" +%s)
          END_TS=$(date -d "$UPDATED_AT" +%s)
          DURATION=$((END_TS - START_TS))
          
          echo "Checking Run $ID: $CONCLUSION, Duration: ${DURATION}s"
          
          # Threshold for a "Real" run (not a skipped check)
          if [ "$DURATION" -gt 30 ]; then
            echo "Found last REAL run: $ID ($CONCLUSION)"
            
            if [ "$CONCLUSION" == "failure" ]; then
              echo "Last real run failed. Stopping automatic execution."
              exit 1
            elif [ "$CONCLUSION" == "success" ]; then
              ELAPSED=$((NOW - END_TS))
              echo "Time since finish: ${ELAPSED}s (Required: 900s)"
              
              if [ "$ELAPSED" -lt 900 ]; then
                echo "Less than 15 minutes since last success. Skipping."
                exit 0 # Success exit to skip gracefully
              else
                echo "More than 15 minutes. Proceeding."
                # We break the loop and let the workflow continue
                # To break the outer script from the subshell loop, we need a flag or exit code trick.
                # Actually, 'exit 0' inside the loop exits the subshell, not the script?
                # No, pipe creates subshell.
                # Let's use a file flag.
                echo "PROCEED" > run_decision.txt
                break
              fi
            fi
            break # Found the real run, stop looking
          else
            echo "Run $ID was too short (${DURATION}s), likely a skipped check. Ignoring."
          fi
        done
        
        # Check decision
        if [ -f run_decision.txt ]; then
           DECISION=$(cat run_decision.txt)
           if [ "$DECISION" == "PROCEED" ]; then
             exit 0
           fi
        fi
        
        # If we exited the loop via 'exit 0' (skip) or 'exit 1' (fail), it might be trapped in the pipe.
        # Wait, if the loop exits with 1, the script continues?
        # Let's refine the logic to avoid pipe subshell issues.
        # We can just iterate with an index.
        
    - name: Smart Schedule Logic (Refined)
      if: github.event_name == 'schedule'
      env:
        GH_TOKEN: ${{ github.token }}
      run: |
        # Fetch last 5 runs
        json=$(gh run list --workflow pipeline_extract_emails.yml --status completed --limit 5 --json conclusion,createdAt,updatedAt)
        
        # Use Python for easier date math/logic than bash/jq
        python3 -c "
        import sys, json, datetime
        from datetime import timezone

        data = json.loads('''$json''')
        now = datetime.datetime.now(timezone.utc)
        
        found_real_run = False
        
        for run in data:
            start = datetime.datetime.fromisoformat(run['createdAt'].replace('Z', '+00:00'))
            end = datetime.datetime.fromisoformat(run['updatedAt'].replace('Z', '+00:00'))
            duration = (end - start).total_seconds()
            
            print(f'Checking run: {run[\"conclusion\"]}, Duration: {duration}s')
            
            if duration > 30:
                found_real_run = True
                if run['conclusion'] == 'failure':
                    print('Last real run FAILED. Stopping.')
                    sys.exit(1) # Fail the step
                
                elapsed = (now - end).total_seconds()
                print(f'Elapsed since finish: {elapsed}s')
                
                if elapsed < 900: # 15 mins
                    print('Too soon (< 15m). Skipping.')
                    # We want to stop the workflow but mark as Success (Skipped)
                    # GitHub Actions doesn't have 'stop this job now' command easily.
                    # We can set an output and use 'if' on subsequent steps.
                    print('::set-output name=skip::true')
                else:
                    print('Time OK. Proceeding.')
                    print('::set-output name=skip::false')
                
                break
        
        if not found_real_run:
            print('No recent real runs found. Proceeding.')
            print('::set-output name=skip::false')
        " > script_output.txt
        
        # Check exit code of python script (sys.exit(1) will fail the step)
        # But we also need to capture the output for the 'skip' logic.
        # The python script prints to stdout, which we see in logs.
        # The ::set-output is deprecated, we should use GITHUB_OUTPUT.
        
    - name: Smart Schedule Logic (Final)
      if: github.event_name == 'schedule'
      id: check_schedule
      env:
        GH_TOKEN: ${{ github.token }}
      run: |
        json=$(gh run list --workflow pipeline_extract_emails.yml --status completed --limit 10 --json conclusion,createdAt,updatedAt)
        
        python3 -c "
        import sys, json, datetime, os
        from datetime import timezone

        try:
            data = json.loads('''$json''')
        except:
            data = []

        now = datetime.datetime.now(timezone.utc)
        found_real_run = False
        should_skip = 'false'
        
        for run in data:
            start = datetime.datetime.fromisoformat(run['createdAt'].replace('Z', '+00:00'))
            end = datetime.datetime.fromisoformat(run['updatedAt'].replace('Z', '+00:00'))
            duration = (end - start).total_seconds()
            
            print(f'Run {run.get(\"databaseId\")}: {run[\"conclusion\"]}, {duration}s')
            
            if duration > 45: # 45s threshold to be safe
                found_real_run = True
                if run['conclusion'] == 'failure':
                    print('Last real run FAILED. Aborting.')
                    sys.exit(1) # Fail the job
                
                elapsed = (now - end).total_seconds()
                print(f'Elapsed: {elapsed}s')
                
                if elapsed < 900:
                    print('Too soon. Skipping.')
                    should_skip = 'true'
                else:
                    print('Time OK.')
                break
        
        with open(os.environ['GITHUB_OUTPUT'], 'a') as fh:
            fh.write(f'skip={should_skip}\n')
        "
        
    - name: Stop if Skipping
      if: steps.check_schedule.outputs.skip == 'true'
      run: |
        echo "Skipping this run (Gap < 15 mins)."
        exit 0 # This marks step as success, but we need to stop subsequent steps.
        # There is no 'exit workflow' command.
        # We must use 'if' conditions on ALL subsequent steps.
        # Or fail? If we fail, it looks red. User wants 'Success' probably?
        # Actually, user said 'Change logic so it launches...'.
        # If I fail, the next check sees a Failure and stops forever.
        # So I MUST succeed.
        # I will cancel the workflow using API? No, that's 'Cancelled'.
        # I will just let this step pass, and add 'if: steps.check_schedule.outputs.skip != 'true'' to the main step.

    - name: Checkout repository
      if: steps.check_schedule.outputs.skip != 'true'
      uses: actions/checkout@v3

    - name: Authenticate to Google Cloud
      if: steps.check_schedule.outputs.skip != 'true'
      uses: google-github-actions/auth@v1
      with:
        workload_identity_provider: 'projects/1043232809378/locations/global/workloadIdentityPools/github-pool/providers/github-provider'
        service_account: 'github-actions-sa@cv-to-cbz-cv.iam.gserviceaccount.com'

    - name: Set up Python
      if: steps.check_schedule.outputs.skip != 'true'
      uses: actions/setup-python@v4
      with:
        python-version: '3.11'

    - name: Install dependencies
      if: steps.check_schedule.outputs.skip != 'true'
      run: |
        python -m pip install --upgrade pip
        pip install google-api-python-client google-auth-httplib2 google-auth-oauthlib PyMuPDF python-docx

    - name: Run script
      if: steps.check_schedule.outputs.skip != 'true'
      env:
        EMAIL_SHEET_ID: ${{ secrets.EMAIL_SHEET_ID }}
        EMAIL_SOURCE_FOLDER_ID: ${{ secrets.EMAIL_SOURCE_FOLDER_ID }}
        EMAIL_SHEET_NAME: ${{ secrets.EMAIL_SHEET_NAME }}
      run: python extract_emails.py --folder_id "$EMAIL_SOURCE_FOLDER_ID" --sheet_id "$EMAIL_SHEET_ID" --sheet_name "$EMAIL_SHEET_NAME":-Feuille 1}"
        python extract_emails.py --folder_id "$EMAIL_SOURCE_FOLDER_ID" --sheet_id "$EMAIL_SHEET_ID" --sheet_name "$SHEET_NAME"
